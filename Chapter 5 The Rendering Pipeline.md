# <element id = "5"> Chapter 5 THE RENDERING PIPELINE </element>

本章主要介绍的是渲染管道。
给你一个3D场景和一个摄像机，渲染管道的任务就是将摄像机看到的内容绘制到一个2D的图片上面来(图片[5.1](#Image5.1))。
这一章的大部分内容是理论知识，下一章我们将会使用`Direct3D`来练习如何绘制。
在我们开始讲渲染管道之前，我们还有两个小部分内容需要先讲：首先会讲到一些3D错觉(即我们通过一个2D屏幕去看一个3D的世界)，然后我们将会解释颜色是如何呈现的。

**目标**

-  掌握用2D图片去描述一个3D物体的关键。
-  发现我们如何使用`Direct3D`呈现3D物体。
-  学习摄像机的定义。
-  理解渲染管道，即将3D场景处理成2D图片的过程。

<img src="Images/5.1.png" id = "Image5.1"> </img>

最左边图片是从侧面看的情况，中间那张是从上面看到情况，最右边那张就是摄像机那个位置看的情况。
我们可以看到从摄像机那里出现了一个4棱锥，我们称之为视锥体，我们能够看到的范围就是视锥体的范围，在视锥体范围外的我们是没有办法看见的。


## <element id = "5.1"> 5.1 THE 3D ILLUSION </element>

在我们踏上3D计算机图形之旅之前，我们还有一个简单的问题没有解决。
我们如何将一个3D场景显示到一个2D屏幕上去。
幸好的是，这个问题已经研究的很深了，就如同艺术家们研究了几个世纪如何将景象更好的画到画板上一样。
在本段中，我们将列出几个让图片更接近3D场景的关键技术。

假设你看到一条没有弯曲的很长的铁路，我们知道这条铁路两边的铁轨肯定是平行的，但是你站在铁路上看铁路的话，你会发现铁路的两边离你离的越远就靠得越近，当距离到达无限的时候，他们就会相交了。
这是我们人类的视觉系统的一个特点，平行线在远处会看做相交于一个点了。参见图片[5.2](#Image5.2)。

<img src="Images/5.2.png" id = "Image5.2"> </img>

另一个特点就是物体的大小会随着距离的增大而显得变小。即同一个物体离我们近的看起来会比离我们远的大。
例如一个离我们远的房子会看起来很小，而离我们近的一棵树却会看起来很大。
图片[5.3](#Image5.3)就显示了物体按照离摄像机的距离摆放，离的越远的物体看起来越小，但其实他们的大小一样大。
同样你也会发现当他们离的足够远的时候，他们就会看起来变成了一个点了。

<img src="Images/5.3.png" id = "Image5.3"> </img>

我们知道物体会重叠(参见图片[5.4](#Image5.4))。
不透明的物体遮住了在他后面的物体的一部分。
这是一个很重要的分辨能力，即通过这个场景能够得到物体的远近关系的能力。
我们已经在第4章讨论了`Direct3D`将会使用深度缓冲来讨论一个像素是否会被遮挡以及是否需要绘制。

<img src="Images/5.4.png" id = "Image5.4"> </img>

思考图片[5.5](#Image5.5)。左边是一个没有光照的球，右边是有一个光照的球。
你可以发先左边的球比较扁平，甚至他可能不是球，只是一个圆。
可以从这里看出，光照和阴影对描述一个实体的3D物体有很大作用。

<img src="Images/5.5.png" id = "Image5.5"> </img>

最后，图片[5.6](#Image5.6)显示了一个飞船和他的影子。
他的影子给我们提供了两个关键的信息，第一个是它告诉我们了光源在哪，第二个是它告诉我们了他距离地面的高度。

<img src="Images/5.6.png" id = "Image5.6"> </img>

虽然这都是日常中很常见的情况，但是这能够帮助我们明确和整理清楚这些东西，也能让我们在学习和使用3D计算机图形的时候将这些现象保留在脑海里面不至于遗忘或者忽略。

## <element id = "5.2"> 5.2 MODEL REPRESENTATION </element>

一个单纯的3D物体可以近似的用三角形网格去呈现。
因此三角形就是我们构建模型的基础的部分。
图片[5.7](#Image5.7)我们可以看到一些3D物体使用三角形网格来绘制。
通常来说如果你使用的三角形数量越多，你就可以让你的模型的细节更加丰富。
但同样的也会带来效率上的负担，你需要处理的三角形就会越多。因此两者之间需要平衡好。
在另外的一些情况下，我们可能需要绘制的是点和线，例如我们需要绘制一条曲线，我们就会使用多个线段来逼近这个曲线。

<img src="Images/5.7.png" id = "Image5.7"> </img>

可以看出图片[5.7](#Image5.7)中的模型是由三角形描绘而成的。
由于很多模型的三角形数量很多，因此构建一个模型就变得及其麻烦。
也因此出现了一些特殊的程序用来设计和构建模型。
这些软件能够让我们使用很多工具并且可视化的设计和构建模型。
例如[3D Studio Max](https://www.autodesk.com/products/3ds-max/overview), [LightWave 3D](https://www.lightwave3d.com/), [Maya](https://www.autodesk.com/products/maya/overview), [Softimage|XSI](https://www.autodesk.com/products/softimage/overview), [Blender](https://www.blender.org/)(免费开源)。

在本书中，我们通常手工构建模型或者使用数学公式构建一些简单模型，例如球体，圆锥，圆柱等。
在本书的第三部分，我们将会演示如何加载一个模型并且绘制他。

## <element id = "5.3"> 5.3 BASIC COMPUTER COLOR </element>

计算机的显示器的每一个像素其实就是通过将红光，绿光，蓝光混合发出，从而显示出各种颜色。
当混合的光射到眼睛里的视网膜的时候，视网膜细胞感受到刺激发出神经冲动到我们的大脑，然后大脑将这个冲动重新识别为颜色。
如果光的混合比例(**即光的强度**)不同，那么发出的神经冲动也会不同，从而大脑也会识别成不同的颜色。
图片[5.8](#Image5.8)举出了一些不同比例的混合会得到什么颜色的例子，以及不同强度下的红光。
因此我们就可以混合不同强度的光来得到各种各样的颜色和我们需要的颜色。

描述一个颜色有很多种方法，其中在程序中最合适的就是使用`RGB`(**red, green, blue**)来描述，例如**Adobe Photoshop**和**Win32**的选择颜色框。

<img src="Images/5.8.png" id = "Image5.8"> </img>

<img src="Images/5.9.png" id = "Image5.9"> </img>

一个显示器发出的不同的颜色的光的强度也是有限制的。
因此我们使用 **[0.0, 1.0]** 这个范围的值来描述光的强度，0即代表没有，1即代表最大强度。
例如 **(0.25, 0.67, 1.00)** 就意味着 **25%** 的红光， **67%** 的绿光和 **100%** 的蓝光。
这样的形式也代表着我们可以使用一个三维向量来描述一个颜色，然后向量的每一个维度都可以描述一种颜色的强度。

### <element id = "5.3.1"> 5.3.1 Color Operations </element> 

我们既然使用向量存储颜色，那么也就代表这我们可以对颜色进行一些向量的运算。例如我们可以对颜色做加减。

**<center>(0.0, 0.5, 0) + (0, 0.0, 0.25) = (0.0, 0.5, 0.25)</center>**

**<center>(1, 1, 1) - (1, 1, 0) = (0, 0, 1)</center>**


当然也可以进行乘法。

**<center>0.5 x (1, 1, 1) = (0.5, 0.5, 0.5)</center>**

**<center>(r, g ,b) x (x, y ,z) = (rx, ry, rz)</center>**

我们在进行运算的过程中允许计算出的值在 **[0, 1]** 之外，但是我们将会在呈现到显示器的时候将比0小的看作0，比1大的看作1。

### <element id = "5.3.2"> 5.3.2 128-Bit Color </element>

我们通常还会给记录颜色的向量增加一个分量，阿尔法值(`Alpha`)。
阿尔法分量通常是在混合(`Blending`)用于描述颜色的不透明度。我们现在不使用混合，就当作设置为1就好了。

加入了阿尔法分量后，我们的颜色向量就变成了一个四维向量了(r, g, b, a)。
由于他是一个四维向量，我们可以使用`XMVECTOR`来优化他。当然你也可以使用其他的类似的来优化他。
`XMVECTOR`使用了`SIMD`指令来优化他的运算，它实质上是一个128bit大小的整型变量。具体的使用你可以去看看[DirectXMath](https://msdn.microsoft.com/en-us/library/windows/desktop/hh437833(v=vs.85))。
如果你使用的是C#的话，那么在.NET 4.6.2以上的版本中他已经有了支持了`SIMD`指令的向量。

### <element id = "5.3.3"> 5.3.3 32-Bit Color </element>

我们还有一种32bit大小的类型存储颜色，即每个分量占8bit，他们的取值范围就在 **[0, 255]** 。
我们可以将其存储在一个32位整型里面，每8位占据一个颜色分量。具体你也可以去看[DirectXMath](https://msdn.microsoft.com/en-us/library/windows/desktop/hh437833(v=vs.85))的`XMCOLOR`类型。

32bit大小的颜色也可以将其转换为四维向量的存储方法，做法就是直接将其每个分量除以255，然后得到一个范围在 **[0, 1]** 的浮点类型的值。

例如： 

**<center> (80, 140, 200, 255) ≈ (0.31, 0.55, 0.78, 1.0) </center>**

在`DirectXMath`中也提供了转换的函数，但是需要注意的存储颜色值的顺序。
在`XMCOLOR`中颜色值是按照ARGB顺序(**从高位到低位**)来的。参见图片[5.10](#Image5.10)。

<img src="Images/5.10.png" id = "Image5.10"> </img>

我们使用128位颜色的优势就在于计算的时候的误差会比32位颜色小很多，因为我们有更大的空间存储更大范围更加精确的值，而32位颜色只有8位存储每个颜色分量。
但是在现在的后台缓冲中我们仍然使用32位颜色来存储最后要输出的颜色，毕竟现今大部分显示设备也没有办法充分利用很高的颜色分辨率。

## <element id = "5.4"> 5.4 OVERVIEW OF THE RENDERING PIPELINE </element>

给你一个3D场景和一个摄像机，渲染管道能够将摄像机看到的东西绘制成一张2D的图片。
图片[5.11](#Image5.11)解释了渲染管道的组成，虽然出现了`GPU`资源，但是他并不属于渲染管道。
从`GPU`资源指向渲染管道的某个阶段的箭头表示这个阶段可以读取这些资源，例如我们在像素着色器阶段读取纹理信息。
而从某个阶段指向`GPU`资源的箭头就表示这个阶段可以写入这些资源，例如我们在输出合并阶段向后台缓冲和深度缓冲中写入像素信息。
从图片中可以看出大部分阶段都是可以读取资源而不是写入资源以及一个阶段的输出就是下一个阶段的输入，比如我们在顶点着色器中处理完的数据就会作为几何着色器的输入数据。

<img src="Images/5.11.png" id = "Image5.11"> </img>

## <element id = "5.5"> 5.5 THE INPUT ASSEMBLER STAGE </element>

这个阶段从内存里读取图形数据，即顶点数据和索引数据，然后使用这些数据取组成一些基础图形，例如三角形和线。
索引数据我们待会在后面的部分会提到，他主要是用于描述一个基础图形是由哪些顶点构成的。

### <element id = "5.5.1"> 5.5.1 Vertices </element>

从数学的角度上来说，三角形的顶点就是他两条边的交点，线的顶点就是他的终点和起点。
对于一个简单的点来说，它本身就是他的顶点。图片[5.12](#Image5.12)举出了这些例子。

<img src="Images/5.12.png" id = "Image5.12"> </img>

可以看出三角形的三个顶点是(**v<sub>0</sub>, v<sub>1</sub>, v<sub>2</sub>**)，线的顶点是(**p<sub>0</sub>, p<sub>1</sub>**)，而点的顶点是它本身**Q**。

从图片[5.12](#Image5.12)中可以看出顶点只是图形中的一些特殊的点。
但是在`Direct3D`中，顶点并没有那么简单。他还可以附加一些其他信息从而去实现一些复杂的特效。
例如在第8章中我们就会在顶点数据中存储法向量来实现光照，并且在第9章的时候我们会增加存储纹理坐标来实现纹理的采样。
我们可以自由的定义顶点存储的数据，准确来说我们可以在`Direct3D`中自由的组合一些分量(例如法向量，纹理坐标，顶点颜色等)来构成顶点。

### <element id = "5.5.2"> 5.5.2 Primitive Topology </element>

我们通过使用顶点缓冲来绑定顶点数据到渲染管道，准确来说顶点缓冲也只是一个缓冲而已。
一个顶点缓冲存储一组顶点数据，但这并不意味着一个顶点缓冲只存储一个图形的顶点数据，他可以存储多个图形的数据。

这些顶点在绘制图形的时候会组合起来，组合的方式是由我们自己来决定的，我们可以决定是使用线组合，还是使用三角形来组合等待方式。

```C++
    void ID3D12GraphicsCommandList::IASetPrimitiveTopology(
        D3D_PRIMITIVE_TOPOLOGY Topology);
```

这个函数会设置构成图形的方式，即我们使用什么基础图形来组合我们要绘制的图形。

`D3D_PRIMITIVE_TOPOLOGY`可以去看文档了解具体有哪些枚举。

注意下面说的点是允许重复的。

#### <element id = "5.5.2.1"> 5.5.2.1 Point List </element>

直接绘制顶点，具体参见图片[5.13](#Image5.13)的a部分。

#### <element id = "5.5.2.2"> 5.5.2.2 Line Strip </element>

将顶点按照顺序用线连接起来，具体参见图片[5.13](#Image5.13)的b部分。
即n+1个点会构成n条线。

#### <element id = "5.5.2.3"> 5.5.2.3 Line List </element>

将给的点按照顺序两个两个一组用线连接起来，具体参见图片[5.13](#Image5.13)的c部分。
即2n个点构成了n条线。

#### <element id = "5.5.2.4"> 5.5.2.4 Triangle Strip </element>

将顶点按照顺序连接成三角形，具体参见图片[5.13](#Image5.13)的d部分。
即n+2个点构成了n个三角形。

<img src="Images/5.13.png" id = "Image5.13"> </img>

#### <element id = "5.5.2.5"> 5.5.2.5 Triangle List </element>

将给点的点按照顺序三个三个一组构成三角形，具体参见图片[5.14](#Image5.14)的a部分。
即3n个点构成了n个三角形。

<img src="Images/5.14.png" id = "Image5.14"> </img>

#### <element id = "5.5.2.6"> 5.5.2.6 Primitives with Adjacency </element>

我们在几何着色器中使用一些算法的时候可能需要去找一个三角形的邻边三角形。
对于邻边三角形具体参见图片[5.14](#Image5.14)的b部分。
为了实现这个功能，我们就需要将一个三角形的邻边三角形和他一起绑定到渲染管道中。

需要注意的是，作为邻边三角形绑定到管道上的三角形是不会被渲染的，他只会作为几何着色器的输入数据。
哪怕你没有使用几何着色器它也不会被渲染。

具体细节你可以参见文档。

#### <element id = "5.5.2.7"> 5.5.2.7 Control Point Patch List </element>

具体在14章讨论。

### <element id = "5.5.3"> 5.5.3 Indices </element>

之前已经提到，三角形是构成实体3D物体的基础。下面的代码分别使用顶点构造了一个四边形和八边形。

```C++
    Vertex quad[6] = {
        v0, v1, v2, //Triangle 0
        v0, v2, v3  //Triangle 1
    };

    Vertex octagon[24] = {
        v0, v1, v2, //Triangle n
        v0, v2, v3,
        v0, v3, v4,
        v0, v4, v5,
        v0, v5, v6,
        v0, v6, v7,
        v0, v7, v8,
        v0, v8, v1
    };
```

构建三角形的三个点的顺序是很重要的，它将决定这个面是正面还是反面，具体会在[**5.10.2**](#5.10.2)中解释。

从图片[5.15](#Image5.15)可以看出来一个顶点在3D物体中可能会被共用很多次。
例如在[5.15](#Image5.15)的a部分中，**v0**和**v2**就被两个三角形共用了。
而在[5.15](#Image5.15)的b部分中，每个三角形都包括**v0**这个顶点，每两个相邻的三角形就共用两个顶点。
可以看出当图形越来越复杂越来越详细的时候，我们共用的顶点就会越来越多，这无疑是一种浪费。

<img src="Images/5.15.png" id = "Image5.15"> </img>

使用重复的顶点有两个主要的不好的影响：

- 增加内存使用量。
- 图形硬件要处理同样的顶点多次，这无疑会增加时间开销。

在某些情况下或许我们可以使用三角形带(**Triangle Strip**)来解决这个问题。
但是三角形组(**Triangle List**)比三角形带更加灵活，有些图形是三角形带没法描绘的，比如两个不相连的三角形。
因此就出现了索引(**Indices**)这一概念。

我们创建两组缓冲，第一组存储我们要绘制的图形的顶点数据，顶点顺序无所谓并且不包含重复顶点。
第二组缓冲就通过使用第一组中的顶点数据来构建三角形从而构造3D图形。那么之前的例子就可以这样表示了。

```C++
    Vertex v[4] = { v0, v1, v2, v3};

    UINT indexList[6] = {
        0, 1, 2, //Triangle 0
        0, 2, 3 //Triangle 1
    };
```

在索引数组里面，每三个元素就表示一个三角形，即 **v[0], v[1], v[2]** 构成一个三角形， **v[0], v[2], v[3]** 构成一个三角形。

```C++
    Vertex v[9] = { v0..v8};

    UINT indexList[24] = {
        0, 1, 2, //Triangle n
        0, 2, 3,
        0, 3, 4,
        0, 4, 5,
        0, 5, 6,
        0, 6, 7,
        0, 7, 8,
        0, 8, 1
    };
```

在处理完这些顶点后，显卡就可以使用索引数据来构建三角形，严格来说顶点共用还是存在，但是相比之前的做法好了很多。

- 索引只是一个整型变量，相比一个顶点所占的内存，一个索引占的内存少了很多。
- 对于每个顶点数据只需要处理一次，而不像之前的方法一个顶点重复几次就处理几次。

## <element id = "5.6"> 5.6 THE VERTEX SHADER STAGE </element>

每个顶点在被用于绘制的时候我们都需要对其进行一些处理，这个过程是由我们自己来给定的(**使用HLSL编写**)。
大致你可以认为是这样的一个过程。

```C++
    for (UINT i = 0; i < numVertices; ++i)
        outputVertex[i] = VertexShader(inputVertex[i]);
```

`VertexShader`这个函数由我们自己来实现，但是它并不是由`CPU`去执行，而是由`GPU`去执行，因此哪怕是处理每个顶点所需要的时间开销也并不大。

很多特效可以在顶点着色器(`VertexShader`)中实现例如对顶点进行变换，光照以及对纹理进行位移。
在顶点着色器里面我们不但可以访问输入的顶点数据并且我们还可以访问存储在显存中的纹理数据或者其他缓冲，比如变换矩阵，场景的光源什么的。

### <element id = "5.6.1"> 5.6.1 Local Space and World Space </element>

当我们在制作一个场景的时候，场景中的模型通常是分开来做的。
我们在制作模型的时候并不会使用同样的坐标系，即这个场景中的坐标系，我们称之为世界坐标系，所在的空间称之为世界空间。
而是使用另外的坐标系，我们称之为模型坐标系或者本地坐标系。
因为在构建模型的时候你使用本地坐标系会比使用世界坐标系方便很多，我们可以针对这个模型来建立模型坐标系而不是使用固定的世界坐标系。
我相信各位都做过立体几何的数学题，建系的位置很大程度上决定了难易程度。
但是这样做的话，我们就必须对其进行一些转换来将其放置到场景中我们想要放置的位置(严格来说这样的转换是对其坐标系的轴和原点进行转换，而模型本身并没有变换，但是因为坐标系的改变，模型在世界坐标系中肯定也会改变，参见图片[5.16](#Image5.16))。
这样的过程我们叫做世界变换(**World Transform**)，将模型坐标系转换的矩阵我们称之为世界矩阵(**World Matrix**)。
场景中的每个物体都应该有一个自己的世界矩阵，这样的话我们模型的构建就和具体场景无关了，我们可以在构建模型的时候不需要考虑具体的场景了(这些问题就又强加给程序员啦)。

<img src="Images/5.16.png" id = "Image5.16"> </img>

模型的每个顶点都是定义模型坐标系中的，如果我们想要将一个模型放到世界坐标中的一个位置，那么我们是需要对其进行变换的。
从某种角度上说这样的变换其实就是改变了模型坐标系的坐标轴和原点。

<img src="Images/5.17.png" id = "Image5.17"> </img>

如果我们以原点作为正方体的中心，并且正方体的三边分别和坐标轴平行的话，我们是很容易就可以算出它8个顶点的坐标。
而如果不是这样的话，那么我要算出正方体8个顶点的坐标就不是那么简单了。
因此我们就定义了模型坐标系来方便我们构建模型。

使用模型坐标系的优点:

- 简单，通常我们都是将原点作为模型的中心，然后选择一个主要的坐标轴将模型分割成对称的两半(也未必完全对称，只是布局上大致对称)。
- 可以在多个场景中重复使用。因为我们构建模型的时候本身就和世界坐标系无关了，那么我们只需要简单的改变下他的世界矩阵就可以用于其他场景了。
- 有时候我们可能在一个场景中绘制多个这样的物体，每个物体不同的地方只是在于它的变换矩阵不同。那么我们就没有必要处理每个实例(即物体)了，我们只需要记录下它在模型坐标系中的信息(即顶点和索引缓冲)，然后在绘制的时候使用对应的世界矩阵就可以完成绘制了。这样的方法我们称之为`Instancing`。

**由于现在对数学公式很不友好，因此下面和矩阵有关的就略过了，你可以去查阅这部分相关内容，世界矩阵很多博客上都会讲到。**

### <element id = "5.6.2"> View Space </element>

在3D场景中我们肯定是需要一个观察这个场景的摄像机。
摄像机会定义一块可视区域，表示这一块区域将会被看到，或者说被摄像机拍到，同时这一块区域也是我们需要将其渲染到2D平面上的区域。
我们定义摄像机的模型坐标系叫做摄像机坐标系或者视角坐标系，所在的空间我们就称之为视角空间。
观察图片[5.19](#Image5.19)。
摄像机在坐标系的原点，然后X轴在摄像机的右方，Y轴在摄像机的上方，Z轴朝向纸面。
除了将物体转换到世界坐标系外，我们在渲染管道的之后的某个阶段也需要重新将物体转换到摄像机坐标系。
我们将物体从世界坐标系转换到视角坐标系的过程叫做视角变换(**View Transform**)，转换的矩阵就叫做视角矩阵了。

<img src="Images/5.19.png" id = "Image5.19"> </img>

**矩阵部分了，等以后打出PDF的时候再考虑补了。其实我觉得我这种数学渣去讲这东西估计没人看得懂。**

**矩阵的话要注意左手和右手坐标系，视角矩阵和投影矩阵都分左右手坐标系。**


### <element id = "5.6.3"> 5.6.3 Projection and Homogeneous Clip Space </element> 

我们已经介绍了摄像机的位置和朝向这两个属性，现在我们介绍摄像机的另外一个属性，摄像机的可视范围。
我们通常使用一个平截头体来规定摄像机的可视范围，参见图片[5.21](#Image5.21)。

<img src="Images/5.21.png" id = "Image5.21"> </img>

而我们需要做的就是将在平截头体内部的3D图形投影到2D的平面上去。
并且我们投影后的图形必须满足平行线最后要交于一个点以及物体会随着距离越远越小。
而透视投影恰好可以做到这些，具体参见图片[5.22](#Image5.22)。
我们把一个顶点和摄像机的位置的连线叫做这个点的投影线，那么我们就可以得到透视投影的变换就是将顶点**v**变换到投影线和投影窗口的交点**v'**，我们就称 **v'** 为**v**的投影。
对于一个3D图形来说他的投影就是将它的所有顶点进行投影后的图形。

<img src="Images/5.22.png" id = "Image5.22"> </img>

#### <element id = "5.6.3.1"> 5.6.3.1 Defining a Frustum </element>

我们需要在视角空间中描述一个平截头体，并且这个平截头体的中心要在原点以及它朝向Z轴的正半轴。
我们使用如下4个参数来描述它，一个近平面`n`,一个远平面`f`,竖直视野角度大小`α`以及长宽比`r`。
在视角空间中，远平面和近平面是和XY轴构成的平面平行的，因此我们只需要确定这两个平面到原点的距离就好了。
长宽比`r=w / h`，即投影的平面的宽度(**Width**)除以高度(**Height**)。
由于我们之后要将投影窗口的内容映射到后台缓冲中去，因此我们需要确定投影窗口的长宽比要和后台缓冲一致。
因此我们可以认为后台缓冲的大小将会决定投影窗口的长宽比。例如后台缓冲的大小是`800x600`，那么我们就设`r`为`r = 800/600 ≈ 1.333`
如果长宽比和后台缓冲的大小不一致的话，我们就会在映射的时候将其进行缩放，**但是这样的缩放宽度和高度缩放的值未必一样**，因此可能会导致图形变形，例如圆可能会变成椭圆。

我们设水平视野角度为`β`，由于我们确定了竖直视野角度`α`以及长宽比`r`，因此`β`的值并不需要我们设定，我们可以计算出来。
参见图片[5.23](#Image5.23)，我们首先可以知道投影窗口的大小并不重要，为了方便我们就认为投影窗口的高度为2，宽度的话就可以通过长宽比来得到。

<img src="Images/5.23.png" id = "Image5.23"> </img>

为了保证水平视野角度`α`，因此投影窗口到原点的距离`d`并不是随意的，我们需要计算出来。

**<center>tan (α/2) = 1 / d => d = cot (α/2)</center>**

因此我们就可以算出投影窗口(**高度为2**)到原点的距离`d`了。
我们因此也可以算出`β`:

**<center>tan (β/2) = r / d = r / cot(α/2)</center>**

**<center>tan (β/2) = r * tan(α/2)</center>**

**<center>β = 2 tan <sup>-1</sup> (r * tan (α/2))</center>**

<img src="Images/5.24.png" id = "Image5.24"> </img>

#### <element id = "5.6.3.2"> 5.6.3.2 Projecting Vertices </element>

我们看图片[5.24](#Image5.24)，给你一个点 **(x, y, z)**，我们需要找到他在平面(**z = d**)上面的投影 **(x', y', d)**。
我们可以得到下面的式子(**先用图片顶替吧哎QAQ**)。

<img src="Images/math1.png" id = "math1"> </img>

因此如果一个点他在这个平截头体里面的话，那么它投影后的点必然在投影窗口内，当然这个点的Z轴坐标必然要在 **(n, f)** 内。

#### <element id = "5.6.3.3"> Normalized Device Coordinates (NDC) </element>

我们在先前的章节计算了一个顶点投影后的坐标。
并且我们知道在视角空间中，投影窗口的高度是**2**，他的宽度是**2r**(`r`是长宽比)。
也就是说投影窗口的大小就由`r`来决定。
因此我们的硬件在处理关于投影窗口的操作(例如将投影窗口的内容映射到后台缓冲中去)的时候是肯定需要知道`r`的，因此我们需要告诉硬件`r`的值。
那么如果我们能够将这些操作变成和`r`无关的话，那么就更好了。
因此我们就对投影的X轴坐标进行缩放，从原本的 **[-r, r]** 到 **[-1, 1]**。即:

**<center>-r ≤ x' ≤ r</center>**

**<center>-1 ≤ x' / r ≤ 1</center>**


经过这样的变换后的坐标系我们称之为标准化设备坐标系(**Normalized Device Coordinates,NDC**)，注意的是我们并没有对Z轴坐标进行任何改变。
这样的话，如果一个点 **(x, y, z)* 在平截头体里的话，就必须满足如下条件:

**<center>-1 ≤ x' / r ≤ 1</center>**

**<center>-1 ≤ y' ≤ 1</center>**

**<center>n ≤ z ≤ f </center>**

我们可以通过使用单位换算的方式来将视角空间的点变换到NDC空间。
我们能够知道在NDC中1个单位(**我们设为ndc**)在视角空间中就是r个单位(**我们设为vs**)。
因此，如果告诉你在视角空间的x坐标，你能够很简单的就将其转换的NDC空间中去(**Y, Z坐标并不需要转换**)。

**<center>x vs * (1 ndc / r vs) = x / r ndc </center>**

因此我们就有了直接将X和Y分量转换到NDC空间的公式了。

**<center>x' = x / (r * z tan (α / 2)) </center>**

**<center>y' = y / (z tan (α / 2)) </center>**

**(eq. 5.1)**

我们可以知道在NDC空间中，投影窗口就变成了一个宽度和高度都为2的正方形了，即我们确定了他的尺寸。
也就是说硬件就不需要知道长宽比也能够处理所有操作了，不过我们也就需要将点转换到NDC坐标系中去。

#### <element id = "5.6.3.4"> 5.6.3.4 Writing the Projection Equations with a Matrix </element>

同样的，我们也可以使用矩阵来表示投影变换。
虽然方程5.1不是线性的，也就是说他并不能直接使用矩阵表示。
因此我们需要使用一些小技巧来构造这个矩阵。
首先我们将方程分为两个部分，线性部分和非线性部分(**非线性部分是除以z，我们之后讨论这个部分**)。
然后我们还需要将Z轴坐标标准化，即将Z值固定在一定范围内。
我们得到的矩阵如下。

<img src="Images/math2.png" id = "math2"> </img>

注意到我们还留下了两个值**A,B**，我们将会使用这两个参数来使得我们的矩阵乘法能够将Z轴的值固定到一定范围。
我们现在给点一个点 **(x, y, z, 1)**。

<img src="Images/math3.png" id = "math3"> </img>

在我们处理完线性部分后，我们还需要将结果处理z来完成非线性部分的运算。

<img src="Images/math4.png" id = "math4"> </img>

如果z是0的话那么我们就会除以0，因此我们的近平面就必须要求大于0，这样的话z为0的点就不会参与投影变换了。
这个除法操作也被称之为透视除法。

#### <element id = "5.6.3.5"> 5.6.3.5 Normalized Depth Value</element>

我们知道投影后所有的能够被看到的点都会在投影窗口上，并且之后他们会构成一张图片来呈现这个3D场景。
然而我们还是需要知道这些点的深度值从而来进行深度测试。我们将XY值投影到一定范围后，我们也有必要将Z值投影到一定范围内 **[0, 1]**。
因此我们就需要构造一个方法将Z轴投影，我们设这个函数来g(z)。
